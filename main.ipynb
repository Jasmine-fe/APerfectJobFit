{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import re\n",
    "import sys\n",
    "import difflib\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "from string import punctuation\n",
    "\n",
    "import importlib\n",
    "importlib.reload(sys.modules['Common'])\n",
    "from Common import getFileNameInDirectory, extractPDFContent, groupbyFirstLetter, getselectedAndUniqueKeywords, filterSimilarityWords\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "directoryPath = '/Users/apple/Desktop/SideProject/ML/APerfectJobFit/Dataset/testResumes'\n",
    "fileNameList = getFileNameInDirectory(directoryPath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "with open('./jobDesciption.txt') as f:\n",
    "    jobDespLines = f.readlines()\n",
    "jobDespText = ''.join(jobDespLines)\n",
    "\n",
    "wordList = [ sentence.split() for sentence in jobDespLines ]\n",
    "flattenWordList = list(itertools.chain(*wordList))\n",
    "porter = PorterStemmer()\n",
    "stemmedWords = [porter.stem(words) for words in flattenWordList]\n",
    "stemmedJobDespText = ' '.join(stemmedWords)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "tokens = nltk.wordpunct_tokenize(jobDespText)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "tokenDf = pd.DataFrame(index = tokens)\n",
    "tokenDf['porter_stemmer'] = [porter_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['lancaster_stemmer'] = [lancaster_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['snowball_stemmer'] = [snowball_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['wordnet_lemmatizer'] = [wordnet_lemmatizer.lemmatize(t) for t in tokens]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "keywordNum = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "idxs = list(tokenDf.columns)\n",
    "keywordDic = dict()\n",
    "for idx in idxs:\n",
    "    tokensList = list(tokenDf[idx])\n",
    "    text = ' '.join(tokensList)\n",
    "    keywordStr = keywords(text, ratio=0.3)\n",
    "    keywordList = re.split('\\n| ', keywordStr )\n",
    "    keywordDic[idx] = keywordList[:keywordNum]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "keywordDf = pd.DataFrame.from_dict(keywordDic)\n",
    "keywordDf.index = keywords(jobDespText, ratio=0.2).split('\\n')[:keywordNum]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "keywordDf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               porter_stemmer lancaster_stemmer snowball_stemmer  \\\n",
       "data                      use              busy              use   \n",
       "business                model               dat            model   \n",
       "experience               busi               sci             busi   \n",
       "experiences              data               job             data   \n",
       "models              scientist             model        scientist   \n",
       "modeling                  job           develop              job   \n",
       "model                 develop            strong          develop   \n",
       "statistical           statist            expery          statist   \n",
       "statistics             comput             techn           comput   \n",
       "development            strong              solv           strong   \n",
       "techniques             experi              stat           experi   \n",
       "regression            regress            comput          regress   \n",
       "tools                techniqu            analys         techniqu   \n",
       "develop custom           tool           company             tool   \n",
       "insights              insight           regress          insight   \n",
       "tree                     tree              tool             tree   \n",
       "trees                   learn           insight            learn   \n",
       "outcomes               outcom               tre           outcom   \n",
       "job                     spark            outcom            spark   \n",
       "learning              analysi             learn          analysi   \n",
       "\n",
       "               wordnet_lemmatizer  \n",
       "data                         data  \n",
       "business                 business  \n",
       "experience                  model  \n",
       "experiences              modeling  \n",
       "models                statistical  \n",
       "modeling               statistics  \n",
       "model                   statistic  \n",
       "statistical           development  \n",
       "statistics              technique  \n",
       "development                strong  \n",
       "techniques             experience  \n",
       "regression             regression  \n",
       "tools                        tool  \n",
       "develop custom            develop  \n",
       "insights                   custom  \n",
       "tree                      insight  \n",
       "trees                    insights  \n",
       "outcomes                 analysis  \n",
       "job                          tree  \n",
       "learning                    trees  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>wordnet_lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>use</td>\n",
       "      <td>busy</td>\n",
       "      <td>use</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>model</td>\n",
       "      <td>dat</td>\n",
       "      <td>model</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>busi</td>\n",
       "      <td>sci</td>\n",
       "      <td>busi</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiences</th>\n",
       "      <td>data</td>\n",
       "      <td>job</td>\n",
       "      <td>data</td>\n",
       "      <td>modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>scientist</td>\n",
       "      <td>model</td>\n",
       "      <td>scientist</td>\n",
       "      <td>statistical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modeling</th>\n",
       "      <td>job</td>\n",
       "      <td>develop</td>\n",
       "      <td>job</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>develop</td>\n",
       "      <td>strong</td>\n",
       "      <td>develop</td>\n",
       "      <td>statistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical</th>\n",
       "      <td>statist</td>\n",
       "      <td>expery</td>\n",
       "      <td>statist</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <td>comput</td>\n",
       "      <td>techn</td>\n",
       "      <td>comput</td>\n",
       "      <td>technique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development</th>\n",
       "      <td>strong</td>\n",
       "      <td>solv</td>\n",
       "      <td>strong</td>\n",
       "      <td>strong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>techniques</th>\n",
       "      <td>experi</td>\n",
       "      <td>stat</td>\n",
       "      <td>experi</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression</th>\n",
       "      <td>regress</td>\n",
       "      <td>comput</td>\n",
       "      <td>regress</td>\n",
       "      <td>regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>techniqu</td>\n",
       "      <td>analys</td>\n",
       "      <td>techniqu</td>\n",
       "      <td>tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>develop custom</th>\n",
       "      <td>tool</td>\n",
       "      <td>company</td>\n",
       "      <td>tool</td>\n",
       "      <td>develop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insights</th>\n",
       "      <td>insight</td>\n",
       "      <td>regress</td>\n",
       "      <td>insight</td>\n",
       "      <td>custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>tree</td>\n",
       "      <td>tool</td>\n",
       "      <td>tree</td>\n",
       "      <td>insight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trees</th>\n",
       "      <td>learn</td>\n",
       "      <td>insight</td>\n",
       "      <td>learn</td>\n",
       "      <td>insights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outcomes</th>\n",
       "      <td>outcom</td>\n",
       "      <td>tre</td>\n",
       "      <td>outcom</td>\n",
       "      <td>analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <td>spark</td>\n",
       "      <td>outcom</td>\n",
       "      <td>spark</td>\n",
       "      <td>tree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>analysi</td>\n",
       "      <td>learn</td>\n",
       "      <td>analysi</td>\n",
       "      <td>trees</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "selectedAndUniqueKeywords = getselectedAndUniqueKeywords(keywordDf)\n",
    "groupbyKeywords = groupbyFirstLetter(selectedAndUniqueKeywords)\n",
    "totalKeywords = [ filterSimilarityWords(words, thresholdRatio=0.7) for words in groupbyKeywords]\n",
    "keywordsList = list(itertools.chain(*totalKeywords))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(\"[ Keyword ]\\n\", ', '.join(keywordsList))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Keyword ]\n",
      " analysi, analysi, analysis, busi, busi, business, comput, comput, custom, data, data, develop, development, experi, experi, experience, insight, insight, insights, job, job, learn, learn, model, model, modeling, outcom, outcom, regress, regress, regression, scientist, scientist, spark, statist, statistic, statistical, statistics, strong, techniqu, techniqu, technique, tool, tree, trees, use, use\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "filePath = './resume_v2.pdf'\n",
    "resumeText = extractPDFContent(filePath)\n",
    "resumeTextList = resumeText.split('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Match Score\n",
    "inputText = [resumeText, jobDespText]\n",
    "cv = CountVectorizer()\n",
    "countMatrix = cv.fit_transform(inputText)\n",
    "matchPercentage = round(cosine_similarity(countMatrix)[0][1] * 100, 2)\n",
    "print(f\"[ Resume Match Score ]\\n{matchPercentage}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Resume Match Score ]\n",
      "65.78\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(f\"[ Summary ]\\n{summarize(jobDespText, ratio=0.1)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Summary ]\n",
      "We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data.\n",
      "The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.\n",
      "Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (conda)"
  },
  "interpreter": {
   "hash": "83cc56e4fb676343596d0be67276f0d6d6c448e87913a0989f441102576e3583"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}