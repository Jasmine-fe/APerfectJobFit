{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import re\n",
    "import difflib\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "from string import punctuation\n",
    "from Common import getFileNameInDirectory, extractPDFContent, groupbyFirstLetter, getselectedAndUniqueKeywords, filterSimilarityWords"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "directoryPath = '/Users/apple/Desktop/SideProject/ML/APerfectJobFit/Dataset/testResumes'\n",
    "fileNameList = getFileNameInDirectory(directoryPath)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open('./jobDesciption.txt') as f:\n",
    "    jobDespLines = f.readlines()\n",
    "jobDespText = ''.join(jobDespLines)\n",
    "\n",
    "wordList = [ sentence.split() for sentence in jobDespLines ]\n",
    "flattenWordList = list(itertools.chain(*wordList))\n",
    "porter = PorterStemmer()\n",
    "stemmedWords = [porter.stem(words) for words in flattenWordList]\n",
    "stemmedJobDespText = ' '.join(stemmedWords)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tokens = nltk.wordpunct_tokenize(jobDespText)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "tokenDf = pd.DataFrame(index = tokens)\n",
    "tokenDf['porter_stemmer'] = [porter_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['lancaster_stemmer'] = [lancaster_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['snowball_stemmer'] = [snowball_stemmer.stem(t) for t in tokens]\n",
    "tokenDf['wordnet_lemmatizer'] = [wordnet_lemmatizer.lemmatize(t) for t in tokens]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "keywordNum = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "idxs = list(tokenDf.columns)\n",
    "keywordDic = dict()\n",
    "for idx in idxs:\n",
    "    tokensList = list(tokenDf[idx])\n",
    "    text = ' '.join(tokensList)\n",
    "    keywordStr = keywords(text, ratio=0.1)\n",
    "    keywordList = re.split('\\n| ', keywordStr )\n",
    "    keywordDic[idx] = keywordList[:keywordNum]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "keywordDf = pd.DataFrame.from_dict(keywordDic)\n",
    "keywordDf.index = keywords(jobDespText, ratio=0.1).split('\\n')[:keywordNum]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "keywordDf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            porter_stemmer lancaster_stemmer snowball_stemmer  \\\n",
       "data                  data               dat             data   \n",
       "business               use              busy              use   \n",
       "experience          experi            expery           experi   \n",
       "experiences          model             model            model   \n",
       "models                busi           develop             busi   \n",
       "modeling           develop             techn          develop   \n",
       "model              statist              solv          statist   \n",
       "statistical         comput              stat           comput   \n",
       "statistics         regress            comput          regress   \n",
       "development       techniqu            analys         techniqu   \n",
       "\n",
       "            wordnet_lemmatizer  \n",
       "data                      data  \n",
       "business              business  \n",
       "experience          experience  \n",
       "experiences              model  \n",
       "models                modeling  \n",
       "modeling           statistical  \n",
       "model               statistics  \n",
       "statistical          statistic  \n",
       "statistics         development  \n",
       "development            develop  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "      <th>wordnet_lemmatizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>data</td>\n",
       "      <td>dat</td>\n",
       "      <td>data</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>use</td>\n",
       "      <td>busy</td>\n",
       "      <td>use</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>experi</td>\n",
       "      <td>expery</td>\n",
       "      <td>experi</td>\n",
       "      <td>experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiences</th>\n",
       "      <td>model</td>\n",
       "      <td>model</td>\n",
       "      <td>model</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>busi</td>\n",
       "      <td>develop</td>\n",
       "      <td>busi</td>\n",
       "      <td>modeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modeling</th>\n",
       "      <td>develop</td>\n",
       "      <td>techn</td>\n",
       "      <td>develop</td>\n",
       "      <td>statistical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>statist</td>\n",
       "      <td>solv</td>\n",
       "      <td>statist</td>\n",
       "      <td>statistics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistical</th>\n",
       "      <td>comput</td>\n",
       "      <td>stat</td>\n",
       "      <td>comput</td>\n",
       "      <td>statistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistics</th>\n",
       "      <td>regress</td>\n",
       "      <td>comput</td>\n",
       "      <td>regress</td>\n",
       "      <td>development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development</th>\n",
       "      <td>techniqu</td>\n",
       "      <td>analys</td>\n",
       "      <td>techniqu</td>\n",
       "      <td>develop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "selectedAndUniqueKeywords = getselectedAndUniqueKeywords(keywordDf)\n",
    "groupbyKeywords = groupbyFirstLetter(selectedAndUniqueKeywords)\n",
    "totalKeywords = [ filterSimilarityWords(words) for words in groupbyKeywords]\n",
    "keywordsList = list(itertools.chain(*totalKeywords))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(\"[ Keyword ]\\n\", ', '.join(keywordsList))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Keyword ]\n",
      " busi, business, comput, data, develop, development, experi, model, regress, statist, techniqu, use\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filePath = './resume_v2.pdf'\n",
    "resumeText = extractPDFContent(filePath)\n",
    "resumeTextList = resumeText.split('\\n')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Match Score\n",
    "inputText = [resumeText, jobDespText]\n",
    "cv = CountVectorizer()\n",
    "countMatrix = cv.fit_transform(inputText)\n",
    "matchPercentage = round(cosine_similarity(countMatrix)[0][1] * 100, 2)\n",
    "print(f\"[ Resume Match Score ]\\n{matchPercentage}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Resume Match Score ]\n",
      "65.78\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"[ Summary ]\\n{summarize(jobDespText, ratio=0.1)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ Summary ]\n",
      "We are looking for a Data Scientist who will support our product, sales, leadership and marketing teams with insights gained from analyzing company data.\n",
      "The ideal candidate is adept at using large data sets to find opportunities for product and process optimization and using models to test the effectiveness of different courses of action.\n",
      "Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (conda)"
  },
  "interpreter": {
   "hash": "83cc56e4fb676343596d0be67276f0d6d6c448e87913a0989f441102576e3583"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}